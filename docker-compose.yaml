x-airflow-common: &airflow-common
  build:
    context: ./data_generation
  environment:
    - SQLALCHEMY_WARN_20=1
    - AIRFLOW__CORE__LOGGING_LEVEL=INFO
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT=60
    - AIRFLOW__CORE__DAGS_FOLDER=/usr/local/airflow/dags
    - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
    - AIRFLOW__WEBSERVER__SECRET_KEY=${SECRET_KEY}
    - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@db/airflow
    # Since Airflow, which is a Docker service, needs to connect to the 2 Kafka brokers, the internal ports of the Kafka brokers are used.
    # the internal port of the first Kafka broker is 29092, and the internal port of the second Kafka broker is 29094.
    - KAFKA_BROKER=kafka1:29092,kafka2:29094
  volumes:
    - ./data_generation:/usr/local/airflow/dags
    - ./data_generation/requirements.txt:/requirements.txt

services:
  zookeeper:
    image: bitnami/zookeeper:3.8.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
      - ALLOW_ANONYMOUS_LOGIN=yes
    healthcheck:
      test: ["CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - streamsnet

  kafka1:
    image: bitnami/kafka:3.8.0
    hostname: kafka1
    container_name: kafka1
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
    # this port enables the local laptop to connect to this broker
      - "9092:9092"
    # this port enables the other services to connect to this broker
      - "29092:29092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT
      # any client can connect to this broker on the internal port 29092 and the connection will be plaintext (unencrypted)
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka1:29092
      - KAFKA_LISTENERS=PLAINTEXT://:29092
      # this variable allows clients to connect to this broker using the plaintext protocol
      - ALLOW_PLAINTEXT_LISTENER=yes
    healthcheck:
      test: ["CMD", "sh", "-c", "kafka-topics.sh --bootstrap-server kafka1:29092 --topic healthcheck --create --if-not-exists && kafka-topics.sh --bootstrap-server kafka1:29092 --describe --topic healthcheck"]
      interval: 5s
      retries: 5
      start_period: 10s
      timeout: 10s
    volumes:
      - kafka1_data:/bitnami/kafka
    networks:
      - streamsnet

  kafka2:
    image: bitnami/kafka:3.8.0
    hostname: kafka2
    container_name: kafka2
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
    # this port enables the local laptop to connect to this broker
      - "9093:9093"
    # this port enables the other services to connect to this broker
      - "29094:29094"
    environment:
      - KAFKA_BROKER_ID=2
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka2:29094
      - KAFKA_LISTENERS=PLAINTEXT://:29094
      - ALLOW_PLAINTEXT_LISTENER=yes
    healthcheck:
      test: ["CMD", "sh", "-c", "kafka-topics.sh --bootstrap-server kafka2:29094 --topic healthcheck --create --if-not-exists && kafka-topics.sh --bootstrap-server kafka2:29094 --describe --topic healthcheck"]
      interval: 5s
      retries: 5
      start_period: 10s
      timeout: 10s
    volumes:
      - kafka2_data:/bitnami/kafka
    networks:
      - streamsnet

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
    ports:
      - "8085:8085"
    environment:
      - SERVER_PORT=8085
    # assigns the name "local"to the Kafka cluster for display in the webserver GUI
      - KAFKA_CLUSTERS_0_NAME=local
    # lists the Kafka brokers the webserver GUI will connect to. because kafka-ui is a Docker service, 
    # the internal ports of the Kafka brokers are used.
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:29092,kafka2:29094
    # defines the Zookeeper connection address
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    networks:
      - streamsnet

  db: 
    image: postgres:13
    container_name: db
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 30s
      timeout: 30s
      retries: 3
    networks:
      - streamsnet

  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    entrypoint: /bin/bash
    command: >
      -c "airflow db init && airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin"
    depends_on:
      db:
        condition: service_healthy
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
    networks:
      - streamsnet

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow_webserver
    command: ["airflow", "webserver"]
    ports:
      - 8080:8080
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    restart: on-failure
    networks:
      - streamsnet

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    command: ["airflow", "scheduler"]
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    restart: on-failure
    networks:
      - streamsnet

  mongodb:
    image: mongo:latest
    container_name: mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${ROOT_PASSWORD}
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    command: --bind_ip 0.0.0.0
    healthcheck: 
      test: ["CMD", "mongosh", "--host", "mongodb", "--eval", "db.runCommand({ ping: 1 }).ok"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 5s
    networks:
      - streamsnet
  
  spark-master:
    image: bitnami/spark:3.5.1
    container_name: spark-master
    command: bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_WEBUI_PORT=8081
    ports:
      - "8081:8081"
      - "7077:7077"
    networks:
      - streamsnet

  spark-worker:
    image: bitnami/spark:3.5.1
    container_name: spark-worker
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_WEBUI_PORT=8082
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1G
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8082:8082"
    networks:
      - streamsnet

networks:
  streamsnet:
    driver: bridge

volumes:
  mongo_data:
  kafka1_data:
  kafka2_data:
  postgres_data: